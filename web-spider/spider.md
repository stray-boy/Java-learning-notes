# 爬虫简介
```
网络爬虫是一种程序，通过自动化地访问网站并收集数据，来自动化地获取信息的方式。它们通常被用来收集互联网上的大量数据，以便进行分析和挖掘。
网络爬虫的基本原理是通过模拟浏览器的行为，自动化地访问网站，并提取相关的信息，例如网页的 HTML、文本、图片等。这些信息可以被保存下来，用于后续的分析和处理。
网络爬虫的应用十分广泛，从搜索引擎的数据收集，到商业情报、社交媒体分析、科学研究等领域都有应用。然而，由于网络爬虫可能会对网站的性能产生影响，一些网站可能会禁止网络爬虫的访问，或者要求遵守一些特定的规则和限制。
需要注意的是，爬虫的使用必须遵守法律和道德规范，不能用于非法的活动，例如网络钓鱼、盗窃等。
```
# 爬虫所使用的库
```
requests
学习爬虫这个是一个绕不过的库
Python的requests库是一个常用的HTTP客户端库，可以方便地发送HTTP请求和获取响应。下面是使用requests库发送HTTP请求的基本步骤：
1、安装requests库：在终端或命令行中使用pip安装requests库，如下所示：
pip install requests
2、导入requests库：在Python代码中导入requests库，如下所示：
import requests
3、发送HTTP请求：使用requests库发送HTTP请求，如下所示：
response = requests.get(url)
```

# 面试


# 个人学习心得
```
对于一些项目需要抓取数据去做保存，能够进行实时计算，所以也就有了学习过程，在这里记录下来。
我学习爬虫的过程主要是使用的python通过requests库还有webdriver这两个，对于逆向之类的有看，但是没有很深的研究，主要分享学习的心得以及记录编程思想，能够精进一步，也希望能对共同学习的人产生帮助。
```

# 优秀爬虫项目
```
欢迎补充
```